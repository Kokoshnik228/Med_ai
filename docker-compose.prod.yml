services:
  qdrant:
    image: qdrant/qdrant:1.13.4
    container_name: medai_qdrant_prod
    restart: unless-stopped
    ports:
      - "7778:6333"
    volumes:
      - qdrant_storage_prod:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "(command -v curl >/dev/null && curl -fsS http://localhost:6333/readyz >/dev/null) || (echo > /dev/tcp/localhost/6333)"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

  ollama:
    image: ollama/ollama:latest
    container_name: medai_ollama_prod
    restart: unless-stopped
    # порт наружу для прода не нужен, app ходит по сети compose
    gpus: "all"
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
      OLLAMA_KEEP_ALIVE: "30m"
    volumes:
      - ollama_models_prod:/root/.ollama
    # healthcheck можно опустить; образ не всегда содержит curl/wget

  app:
    image: med_ai-app:${APP_IMAGE_TAG:-prod}
    container_name: medai_app_prod
    restart: unless-stopped

    depends_on:
      qdrant:
        condition: service_started
      ollama:
        condition: service_started

    gpus: "all"
    shm_size: "2g"

    # Читаем .env.prod (важно!)
    env_file:
      - .env.prod

    environment:
      # Минимум, что задаём явно поверх .env:
      APP_ENV: "prod"
      APP_HOST: "0.0.0.0"
      APP_PORT: "8000"
      WEB_CONCURRENCY: "2"

    ports:
      - "8050:8000"

    volumes:
      - ./data:/app/data
      - ./index:/app/index
      - ./raw_docs:/app/raw_docs
      - hf_cache:/root/.cache/huggingface
      - easyocr_cache:/root/.EasyOCR

    extra_hosts:
      - "host.docker.internal:host-gateway"


    command: ["bash", "start.sh"]

volumes:
  qdrant_storage_prod:
  hf_cache:
  easyocr_cache:
  ollama_models_prod:
