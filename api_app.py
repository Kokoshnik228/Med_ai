#!/usr/bin/env python3
from __future__ import annotations

import json
import os
import re
import socket
import subprocess
import threading
import time
import importlib
from pathlib import Path
from typing import Any, Dict, List, Optional

# ================================
# .env -> runtime_settings (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
# ================================
try:
    from dotenv import load_dotenv
    env_mode = (os.getenv("APP_ENV") or "dev").strip().lower()
    env_file = Path(".env.dev" if env_mode == "dev" else ".env.prod")
    if env_file.exists():
        load_dotenv(dotenv_path=env_file)
        print(f"üîß Loaded env: {env_file}")
except Exception as e:
    print(f"‚ö†Ô∏è dotenv load skipped: {e}")

# runtime settings: –∏–º–ø–æ—Ä—Ç –ü–û–°–õ–ï –∑–∞–≥—Ä—É–∑–∫–∏ .env
from config.runtime_settings import settings  # noqa: E402
try:
    settings.apply_env(force=True)
except Exception:
    pass

# ================================
# –ò–º–ø–æ—Ä—Ç—ã –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
# ================================
from glob import glob  # noqa: F401
import requests
import yaml
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, Field

# pydantic v1/v2 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
try:
    from pydantic import field_validator  # type: ignore
    _P_V2 = True
except Exception:
    from pydantic import validator as field_validator  # type: ignore
    _P_V2 = False

# RAG utils
from rag.bm25_utils import bm25_search, retrieve_hybrid, embed_query_hf  # noqa: F401

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è HTTP-—Å–µ—Å—Å–∏—è (keep-alive)
_HTTP = requests.Session()
_HTTP.headers.update({"Connection": "keep-alive"})

# ----- –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ö–µ–ª–ø–µ—Ä—ã –ø–æ –º–æ–¥–µ–ª—è–º (–∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ runtime) -----
def llm_get_allowed():
    return list(getattr(settings, "LLM_ALLOWED", []) or [])

def llm_get_active():
    return str(getattr(settings, "LLM_ACTIVE", "") or "")

def llm_get_preset(model_id: str) -> dict:
    return dict((getattr(settings, "LLM_PRESETS", {}) or {}).get(model_id, {}))

def llm_get_labels() -> dict:
    pretty = {
        "llama3.1:8b": "Llama 3.1 (8B)",
        "llama3.1:70b": "Llama 3.1 (70B)",
        "deepseek-r1:32b": "DeepSeek R1 (32B)",
    }
    return {m: pretty.get(m, m) for m in llm_get_allowed()}

# ================================
# FastAPI
# ================================
app = FastAPI(title="med_ai RAG API", version="1.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"]
)

def _as_int(v, default):
    try:
        return int(str(v))
    except Exception:
        return default

def _as_float(v, default):
    try:
        return float(str(v))
    except Exception:
        return default

def _llm_conf_from_settings() -> dict:
    d_model       = getattr(settings, "LLM_MODEL", "llama3.1:8b")
    d_base_url    = getattr(settings, "LLM_BASE_URL", "http://ollama:11434")
    d_num_ctx     = getattr(settings, "LLM_NUM_CTX", 4096)
    d_max_tokens  = getattr(settings, "LLM_MAX_TOKENS", 300)
    d_timeout_s   = getattr(settings, "LLM_TIMEOUT", 60)
    d_temp        = 0.4
    d_top_p       = 0.95
    d_repeat_pen  = 1.05
    d_gpu_layers  = -1
    d_keep_alive  = "30m"

    return {
        "model":        os.getenv("LLM_MODEL", d_model),
        "base_url":     os.getenv("LLM_BASE_URL", d_base_url),
        "num_ctx_cap":  _as_int(os.getenv("LLM_NUM_CTX"), d_num_ctx),
        "max_tokens":   _as_int(os.getenv("LLM_MAX_TOKENS"), d_max_tokens),
        "timeout_s":    _as_int(os.getenv("LLM_TIMEOUT"), d_timeout_s),
        "temperature":      _as_float(os.getenv("LLM_TEMPERATURE"), d_temp),
        "top_p":            _as_float(os.getenv("LLM_TOP_P"), d_top_p),
        "repeat_penalty":   _as_float(os.getenv("LLM_REPEAT_PENALTY"), d_repeat_pen),
        "gpu_layers":   _as_int(os.getenv("LLM_NUM_GPU_LAYERS"), d_gpu_layers),
        "keep_alive":   os.getenv("LLM_KEEP_ALIVE", d_keep_alive),
    }

# ================================
# Config (yaml + runtime overrides)
# ================================
ROOT = Path(__file__).resolve().parent
os.chdir(ROOT)
print(f"üìÇ CWD set to: {Path.cwd()}")
CONF_DIR = ROOT / "config"
DEFAULT_YAML = CONF_DIR / "default.yaml"
LOCAL_YAML = CONF_DIR / "local.yaml"

def load_runtime_overrides() -> Dict[str, Any]:
    try:
        import config.runtime_settings as rs  # type: ignore
        importlib.reload(rs)
        data = getattr(rs, "RUNTIME", None)
        if isinstance(data, dict):
            print("üîÅ runtime_settings.py loaded")
            return data
    except Exception as e:
        print(f"‚ö†Ô∏è runtime overrides not loaded: {e}")
    return {}

def env_bool(name: str, default: bool) -> bool:
    v = os.getenv(name)
    if v is None:
        return bool(default)
    v = str(v).strip().lower()
    if v in ("1", "true", "yes", "y", "on"):
        return True
    if v in ("0", "false", "no", "n", "off", ""):
        return False
    try:
        return bool(int(v))
    except Exception:
        return bool(default)

def _env_flag(name: str, default: bool) -> bool:
    v = os.getenv(name)
    if v is None:
        return bool(default)
    return str(v).strip().lower() in ("1", "true", "yes", "on")

def load_config() -> Dict[str, Any]:
    def _load_yaml(p: Path) -> Dict[str, Any]:
        try:
            data = yaml.safe_load(p.read_text(encoding="utf-8")) if p.exists() else {}
            return data if isinstance(data, dict) else {}
        except Exception:
            return {}

    DEFAULTS = {
        "app": {"data_dir": "data", "bm25_index_dir": "index/bm25_idx"},
        "qdrant": {
            "url": os.getenv("QDRANT_URL", "http://qdrant:6333"),
            "collection": os.getenv("QDRANT_COLLECTION", "med_kb_v3"),
        },
        "ollama": {
            "base_url": os.getenv("LLM_BASE_URL", "http://ollama:11434"),
            "model": os.getenv("LLM_MODEL", os.getenv("MODEL_ID", "llama3.1:8b")),
            "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "2048")),
            "timeout_s": int(os.getenv("LLM_TIMEOUT", "60")),
            "temperature": float(os.getenv("LLM_TEMPERATURE", "0.4")),
            "top_p": float(os.getenv("LLM_TOP_P", "0.95")),
            "num_ctx": int(os.getenv("LLM_NUM_CTX", "6144")),
        },
        "retrieval": {"k": settings.RETR_TOP_K},
        "embedding": {
            "backend": os.getenv("EMB_BACKEND", settings.EMB_BACKEND or "hf"),
            "model": os.getenv("HF_MODEL", settings.HF_MODEL or "BAAI/bge-m3"),
            "device": os.getenv("HF_DEVICE", settings.HF_DEVICE or "auto"),
            "fp16": _env_flag("HF_FP16", bool(getattr(settings, "HF_FP16", True))),
        },
        "chunking": {"child_w": 200, "child_overlap": 35, "parent_w": 800},
        "prompt": {
            
                "system": os.getenv("PROMPT_SYSTEM", getattr(settings, "PROMPT_SYSTEM", "")),
                "user_template": os.getenv("PROMPT_USER_TPL", getattr(settings, "PROMPT_USER_TPL", "")),
            
        },
    }

    base = _load_yaml(DEFAULT_YAML)
    local = _load_yaml(LOCAL_YAML)
    runtime = load_runtime_overrides()

    def merge(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
        out = dict(a)
        for k, v in (b or {}).items():
            if isinstance(v, dict) and isinstance(out.get(k), dict):
                out[k] = merge(out[k], v)
            else:
                out[k] = v
        return out

    return merge(DEFAULTS, merge(base, merge(local, runtime)))

CONFIG = load_config()

def cfg(*path: str, default: Any = None) -> Any:
    cur: Any = CONFIG
    for p in path:
        if not isinstance(cur, dict) or p not in cur:
            return default
        cur = cur[p]
    return cur

def cfg_int(*path, default: int, allow_zero: bool = False) -> int:
    v = cfg(*path, default=None)
    try:
        v = int(v)
        if (not allow_zero and v <= 0) or (allow_zero and v < 0):
            raise ValueError
        return v
    except Exception:
        return int(default)

def cfg_float(*path, default: float) -> float:
    v = cfg(*path, default=None)
    try:
        return float(v)
    except Exception:
        return float(default)

def cfg_str(*path, default: str) -> str:
    v = cfg(*path, default=None)
    return str(v) if (v is not None and str(v).strip() != "") else str(default)

# ================================
# Warmup BM25 (–æ–¥–∏–Ω —Ä–∞–∑)
# ================================
WARMUP_DONE = False

@app.on_event("startup")
def warmup_bm25():
    global WARMUP_DONE
    if WARMUP_DONE or os.getenv("BM25_WARMUP_DISABLED") == "1":
        return
    try:
        idx = settings.BM25_INDEX_DIR
        bm25_search(idx, "—Ç–µ—Å—Ç", topk=1)  # –ø—Ä–æ–≥—Ä–µ–≤ JVM + –∏–Ω–¥–µ–∫—Å–∞
        print("üî• BM25 warmed up")
        WARMUP_DONE = True
    except Exception as e:
        print(f"‚ö†Ô∏è BM25 warmup skipped: {e}")

# ================================
# Utils
# ================================
def looks_meaningless(text: str) -> bool:
    t = (text or "").strip().lower()
    if len(t) < 3:
        return True
    if re.fullmatch(r"[a-z]\d{1,2}(\.\d+)?", t):
        return False
    if not re.search(r"[a-z–∞-—è—ë0-9]", t):
        return True
    letters_only = re.fullmatch(r"[a-z–∞-—è—ë\s]+", t)
    if letters_only and len(set(t)) < 5 and len(t) < 20:
        return True
    return False

def build_context_citations(ctx_items, max_out: int = 5):
    return [f"{it['doc_id']} —Å—Ç—Ä.{it['page_start']}-{it['page_end']}" for it in ctx_items[:max_out]]

def build_ctx_string(ctx_items, max_chars: int = 8000, per_text_limit: int = 800) -> str:
    parts, total = [], 0
    for i, it in enumerate(ctx_items, 1):
        txt = (it.get("text", "") or "")[:per_text_limit]
        chunk = f"### [{i}] DOC {it['doc_id']} P{it['page_start']}-{it['page_end']}\n{txt}\n\n"
        if total + len(chunk) > max_chars:
            break
        parts.append(chunk)
        total += len(chunk)
    return "".join(parts)

def _approx_tokens(s: str) -> int:
    return max(1, len(s) // 4)

# ================================
# Qdrant client (REST)
# ================================
def _qdrant_client_rest(url_override: Optional[str] = None):
    from qdrant_client import QdrantClient
    url = (url_override or cfg("qdrant", "url", default=settings.QDRANT_URL))
    if "qdrant:" in url:
        try:
            socket.gethostbyname("qdrant")
        except socket.gaierror:
            url = "http://localhost:7779"
    return QdrantClient(url=url, timeout=10, prefer_grpc=False, grpc_port=None)

# ================================
# LLM —á–µ—Ä–µ–∑ Ollama ‚Äî helpers
# ================================
def _trim_code_fences(txt: str) -> str:
    txt = re.sub(r"^\s*```(?:json)?\s*", "", txt, flags=re.IGNORECASE)
    txt = re.sub(r"\s*```\s*$", "", txt)
    return txt.strip()

def safe_json_extract(s: str) -> Dict[str, Any]:
    import json as _json, re as _re

    def _default():
        return {
            "score": None, "subscores": {}, "critical_errors": [], "recommendations": [],
            "citations": [], "disclaimer": "–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –Ω–µ —É–¥–∞–ª—Å—è."
        }

    if not s:
        return _default()

    s1 = _re.sub(r"```(?:json)?", "", s, flags=_re.IGNORECASE).replace("```", "").strip()

    try:
        obj = _json.loads(s1)
        if isinstance(obj, str):
            try:
                return _json.loads(obj)
            except Exception:
                pass
        if isinstance(obj, dict):
            return obj
    except Exception:
        pass

    start, depth, best = None, 0, None
    for i, ch in enumerate(s1):
        if ch == "{":
            if depth == 0:
                start = i
            depth += 1
        elif ch == "}" and depth > 0:
            depth -= 1
            if depth == 0 and start is not None:
                cand = (start, i + 1)
                if not best or (cand[1] - cand[0]) > (best[1] - best[0]):
                    best = cand
    if best:
        chunk = s1[best[0]:best[1]]
        try:
            return _json.loads(chunk)
        except Exception:
            chunk2 = _re.sub(r",\s*([}\]])", r"\1", chunk)
            try:
                return _json.loads(chunk2)
            except Exception:
                pass

    try:
        unescaped = s1.encode("utf-8", "ignore").decode("unicode_escape")
        return _json.loads(unescaped)
    except Exception:
        pass

    return _default()

# --- helpers –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞/JSON --------------------------------

_CODE_BLOCK_RE = re.compile(r"```[a-zA-Z0-9_+\-]*\s*([\s\S]*?)```", flags=re.DOTALL)

def _strip_code_fences_strict(s: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π ```–±–ª–æ–∫``` –µ—Å–ª–∏ –æ–Ω —Ü–µ–ª–∏–∫–æ–º; –∏–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ –µ—Å—Ç—å."""
    if not s:
        return ""
    m = _CODE_BLOCK_RE.search(s)
    return m.group(1).strip() if m else s.strip()

def _strip_code_fences_loose(s: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç –¥–∞–∂–µ –ù–ï–ó–ê–ö–†–´–¢–´–ï –Ω–∞—á–∞–ª–∞ –∫–æ–¥–∞: '```json\\n...' ‚Üí —Ç–µ–∫—Å—Ç –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞,
    –∞ —Ç–∞–∫–∂–µ —Å—Ä–µ–∑–∞–µ—Ç —Ö–≤–æ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏.
    """
    if not s:
        return ""
    s = s.replace("\r", "").lstrip()
    if s.startswith("```"):
        p = s.find("\n")
        s = s[p + 1:] if p != -1 else ""
    s = s.rstrip("`").rstrip()
    return s

def _clean_free_text(s: str) -> str:
    """–ß–∏—Å—Ç—ã–π —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç: –±–µ–∑ ```—Ñ–µ–Ω—Å–æ–≤```, –±–µ–∑ –º—É—Å–æ—Ä–∞ –ø–æ –∫—Ä–∞—è–º."""
    if not s:
        return ""
    t = _strip_code_fences_strict(s)
    if "```" in t:
        t = _strip_code_fences_loose(t)
    # —É–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏/–±–µ–∫—Ç–∏–∫–∏ –ø–æ –∫—Ä–∞—è–º
    t = t.strip().strip("`").strip()
    return t

def _try_parse_json_from_text(s: str):
    """–ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–≤ —Ç.—á. –≤–Ω—É—Ç—Ä–∏ ```json ... ``` –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ { ... })."""
    if not s:
        return None
    t = _strip_code_fences_strict(s)
    if t == s:
        t = _strip_code_fences_loose(t)
    t = t.strip()

    # –ø—Ä—è–º–æ–π parse
    try:
        return json.loads(t)
    except Exception:
        pass

    # –≤—ã—Ä–µ–∑–∞—Ç—å –ø–µ—Ä–≤—É—é {...} ¬´—Å–∫–æ–±–æ—á–Ω—É—é¬ª –æ–±–ª–∞—Å—Ç—å
    start = t.find("{")
    end = t.rfind("}")
    if start != -1 and end > start:
        candidate = t[start:end + 1]
        try:
            return json.loads(candidate)
        except Exception:
            pass
    return None

def _extract_any_text(resp) -> str:
    """–î–æ—Å—Ç–∞—ë–º –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä—è-–æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ (raw_stream/raw_block/response/... )."""
    if isinstance(resp, str):
        return resp
    if isinstance(resp, dict):
        for key in ("raw_stream", "raw_block", "response", "text", "message", "content"):
            v = resp.get(key)
            if isinstance(v, str) and v.strip():
                return v
    return ""

def _norm_critical_errors(ce) -> list[dict]:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –∫—Ä–∏—Ç.–æ—à–∏–±–æ–∫ –∫ [{type, explain}]"""
    out = []
    if isinstance(ce, list):
        for item in ce:
            if isinstance(item, dict):
                t = str(item.get("type", "")).strip()
                e = str(item.get("explain", "")).strip()
                if t or e:
                    out.append({"type": t, "explain": e})
            elif isinstance(item, str) and item.strip():
                out.append({"type": "", "explain": item.strip()})
    elif isinstance(ce, str) and ce.strip():
        out.append({"type": "", "explain": ce.strip()})
    return out

def _norm_recommendations(rec) -> list[str]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.
    –ß–∏—Å—Ç–∏–º –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏/–º—É—Å–æ—Ä –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫. –ù–µ –¥—É–±–ª–∏—Ä—É–µ–º –ø—É—Å—Ç—è–∫–∏.
    """
    items: list[str] = []
    if isinstance(rec, str):
        r = _clean_free_text(rec)
        if r:
            items = [r]
    elif isinstance(rec, list):
        for x in rec:
            if isinstance(x, str):
                r = _clean_free_text(x)
                if r:
                    items.append(r)
            elif isinstance(x, dict):
                wt = str(x.get("what_to_change", "")).strip()
                rn = str(x.get("rationale", "")).strip()
                s = f"{wt} ‚Äî {rn}" if wt and rn else (wt or rn)
                s = _clean_free_text(s)
                if s:
                    items.append(s)
            else:
                try:
                    items.append(json.dumps(x, ensure_ascii=False))
                except Exception:
                    pass
    elif rec is not None:
        try:
            s = json.dumps(rec, ensure_ascii=False)
            s = _clean_free_text(s)
            if s:
                items = [s]
        except Exception:
            pass

    # dedup + —Ñ–∏–ª—å—Ç—Ä –ø—É—Å—Ç—ã—Ö
    seen = set()
    out = []
    for it in items:
        t = (it or "").strip()
        if t and t not in seen:
            out.append(t)
            seen.add(t)
    return out

# --- –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è -----------------------------------------------------------

def normalize_result_loose(resp: dict | str) -> dict:
    """
    –ú—è–≥–∫–∞—è —Å—Ö–µ–º–∞:
      - critical_errors: list[{type, explain}]
      - recommendations: [str] (–µ—Å–ª–∏ –±—ã–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ/JSON; –Ω–µ —Ç—è–Ω–µ–º –∏—Ö –∏–∑ ¬´—Å–≤–æ–±–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞¬ª)
      - free_text: str (–ª—é–±–æ–π –Ω–µ-JSON –∫–æ–Ω—Ç–µ–Ω—Ç –º–æ–¥–µ–ª–∏, –æ—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç ``` –∏ –º—É—Å–æ—Ä–∞)
      - meta: dict (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ), –Ω–∞–ø—Ä–∏–º–µ—Ä meta.role = '–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç'
      - citations/disclaimer –º–æ–≥—É—Ç –±—ã—Ç—å, –Ω–æ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã
    """
    out = {
        "critical_errors": [],
        "recommendations": [],
        "citations": [],
        "disclaimer": "",
        "meta": {},
        "free_text": ""
    }

    # --- –≤–∞—Ä–∏–∞–Ω—Ç: –ø—Ä–∏—à–ª–∞ –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∞
    if isinstance(resp, str):
        parsed = _try_parse_json_from_text(resp)
        if isinstance(parsed, dict):
            out["critical_errors"] = _norm_critical_errors(parsed.get("critical_errors"))
            out["recommendations"] = _norm_recommendations(parsed.get("recommendations"))
            if isinstance(parsed.get("meta"), dict):
                out["meta"] = dict(parsed["meta"])
            if isinstance(parsed.get("citations"), list):
                out["citations"] = [str(x) for x in parsed["citations"] if x]
            if isinstance(parsed.get("disclaimer"), str):
                out["disclaimer"] = parsed["disclaimer"]
        else:
            out["free_text"] = _clean_free_text(resp)
        return out

    # --- –≤–∞—Ä–∏–∞–Ω—Ç: –ø—Ä–∏—à—ë–ª —Å–ª–æ–≤–∞—Ä—å
    if not isinstance(resp, dict):
        return out

    # 1) –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ / —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ ‚Äî —Ç–æ–ª—å–∫–æ –∏–∑ ¬´—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö¬ª –ø–æ–ª–µ–π
    out["critical_errors"] = _norm_critical_errors(resp.get("critical_errors"))
    out["recommendations"] = _norm_recommendations(resp.get("recommendations"))

    # 2) meta/citations/disclaimer ‚Äî –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    if isinstance(resp.get("meta"), dict):
        out["meta"] = dict(resp["meta"])
    if isinstance(resp.get("citations"), list):
        out["citations"] = [str(x) for x in resp["citations"] if x]
    if isinstance(resp.get("disclaimer"), str):
        out["disclaimer"] = resp["disclaimer"]

    # 3) —Å–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç ‚Äî –∏–∑ –ª—é–±—ã—Ö ¬´—Å—ã—Ä—å–µ–≤—ã—Ö¬ª –∫–ª—é—á–µ–π
    raw_txt = _extract_any_text(resp)
    if raw_txt:
        # –ï—Å–ª–∏ —Ç–∞–º –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –ª–µ–∂–∏—Ç JSON ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø–æ–ª—è
        parsed = _try_parse_json_from_text(raw_txt)
        if isinstance(parsed, dict):
            # –¥–æ–∑–∞–ø–æ–ª–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏/–∫—Ä–∏—Ç.–æ—à–∏–±–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ –±—ã–ª–æ
            if not out["recommendations"]:
                out["recommendations"] = _norm_recommendations(parsed.get("recommendations"))
            if not out["critical_errors"]:
                out["critical_errors"] = _norm_critical_errors(parsed.get("critical_errors"))
            # free_text –≤—Å—ë —Ä–∞–≤–Ω–æ –æ—Å—Ç–∞–≤–∏–º ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º¬ª
            free = (
                str(parsed.get("answer") or parsed.get("text") or parsed.get("message") or "").strip()
            )
            out["free_text"] = _clean_free_text(free) if free else _clean_free_text(raw_txt)
        else:
            out["free_text"] = _clean_free_text(raw_txt)

    return out

def _ns_to_ms(ns: int) -> int:
    try:
        return int(round(float(ns) / 1_000_000.0))
    except Exception:
        return 0

# --- Ollama HTTP helpers: stream-first, no JSON format on stream ---
import requests as _requests

_HTTP2 = _requests.Session()

def _trim_code_fences2(s: str) -> str:
    s = (s or "").strip()
    if s.startswith("```"):
        s = s.strip("` \n")
        s = s.split("\n", 1)[-1]
    return s.strip()

def safe_json_extract2(s: str) -> Dict[str, Any]:
    s = _trim_code_fences2(s)
    try:
        obj = json.loads(s)
        if isinstance(obj, dict):
            return obj
        return {"result": obj}
    except Exception:
        return {
            "score": None, "subscores": {}, "critical_errors": [], "recommendations": [], "citations": [],
            "disclaimer": "LLM –≤–µ—Ä–Ω—É–ª –Ω–µ-JSON (stream relax)."
        }

def _ollama_generate_stream(
    ollama_url: str,
    payload: Dict[str, Any],
    *,
    per_chunk_timeout_s: float = 30.0,
    connect_timeout_s: float = 3.0,
    enforce_json_on_stream: bool = False,
) -> str:
    """
    –ï—Å–ª–∏ enforce_json_on_stream=True ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º "format":"json" –ø—Ä—è–º–æ –≤ —Å—Ç—Ä–∏–º-–ø–µ–π–ª–æ–∞–¥.
    –≠—Ç–æ –Ω–µ –º–µ—à–∞–µ—Ç –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º—É –≤—ã–≤–æ–¥—É, –Ω–æ –∏—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ 'response' –±—É–¥–µ—Ç JSON.
    """
    import json as _json

    stream_payload = dict(payload)
    stream_payload["stream"] = True
    if enforce_json_on_stream:
        stream_payload["format"] = "json"
    else:
        # –µ—Å–ª–∏ –Ω–µ –Ω–∞–≤—è–∑—ã–≤–∞–µ–º JSON ‚Äî —É–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π format –∏–∑ payload
        stream_payload.pop("format", None)

    with _HTTP2.post(
        f"{ollama_url.rstrip('/')}/api/generate",
        json=stream_payload,
        timeout=(float(connect_timeout_s), float(per_chunk_timeout_s)),
        stream=True,
    ) as r:
        r.raise_for_status()
        buf = []
        for ln in r.iter_lines(decode_unicode=True):
            if not ln:
                continue
            try:
                chunk = _json.loads(ln)
                if "response" in chunk and chunk["response"]:
                    buf.append(chunk["response"])
            except Exception:
                continue
        return "".join(buf)



def call_ollama_json(
    ollama_url: Optional[str],
    model: str,
    system_prompt: str,
    user_prompt: str,
    *,
    connect_timeout_s: float = 3.0,
    read_timeout_s: float = 90.0,
    stream_chunk_timeout_s: float = 30.0,
    num_ctx: int = 6144,
    num_predict: int = 160,
    temperature: float = 0.2,
    extra_options: Optional[Dict[str, Any]] = None,
    options: Optional[Dict[str, Any]] = None,
    keep_alive: Optional[str] = None,
    **_ignored_kwargs,
) -> Dict[str, Any]:
    try:
        if not ollama_url:
            ollama_url = "http://ollama:11434"

        bad = {"gpu_layers", "num_gpu", "main_gpu"}
        opts = {
            "num_ctx": int(num_ctx),
            "num_predict": int(num_predict),
            "temperature": float(temperature),
        }
        if options:
            opts.update({k: v for k, v in options.items() if k not in bad})
        if extra_options:
            opts.update({k: v for k, v in extra_options.items() if k not in bad})

        base_payload = {
            "model": model,
            "prompt": user_prompt,
            "system": system_prompt,
            "options": opts,
        }
        if keep_alive is not None:
            base_payload["keep_alive"] = keep_alive

        raw_stream_text = ""

        # 1) STREAM-FIRST (–±–µ–∑ format=json)
        try:
            print("LLM STREAM: start")
            text = _ollama_generate_stream(
                ollama_url,
                base_payload,
                per_chunk_timeout_s=stream_chunk_timeout_s,
                connect_timeout_s=connect_timeout_s,
                enforce_json_on_stream=False,
            )
            text = _trim_code_fences2(text)
            raw_stream_text = text or ""
            if text:
                parsed = safe_json_extract2(text)
                if isinstance(parsed, dict) and parsed:
                    # –¥–∞–∂–µ –µ—Å–ª–∏ JSON —Ä–∞—Å–ø–∞—Ä—Å–∏–ª—Å—è, –æ—Å—Ç–∞–≤–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                    parsed.setdefault("raw_stream", raw_stream_text)
                    return parsed
                else:
                    # –Ω–µ JSON: –ø–æ–ø—Ä–æ–±—É–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π fallback, –Ω–æ raw_stream –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ—Ä–Ω—ë–º
                    print("LLM STREAM: got non-JSON or unparseable JSON ‚Üí fallback to blocking format=json")
            else:
                print("LLM STREAM: empty stream result")
        except _requests.exceptions.ReadTimeout:
            print(f"LLM STREAM: ReadTimeout (chunk {stream_chunk_timeout_s}s), fallback to short blocking call")
        except Exception as e:
            print(f"LLM STREAM: error={type(e).__name__}: {e}, fallback to blocking")

        # 2) –ö–æ—Ä–æ—Ç–∫–∞—è –±–ª–æ–∫–∏—Ä—É—é—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ c format=json
        short_payload = dict(base_payload)
        short_opts = dict(opts)
        short_opts["num_predict"] = min(80, int(opts.get("num_predict", 120)))
        short_payload["options"] = short_opts
        short_payload["format"] = "json"
        try:
            resp = _HTTP2.post(
                f"{ollama_url.rstrip('/')}/api/generate",
                json=short_payload,
                timeout=(float(connect_timeout_s), float(read_timeout_s)),
            )
            resp.raise_for_status()
            if str(resp.headers.get("content-type", "")).startswith("application/json"):
                obj = resp.json()
                s = obj.get("response", "") if isinstance(obj, dict) else ""
            else:
                s = resp.text or ""
            s = _trim_code_fences2(s)

            if not s:
                out = {
                    "score": None, "subscores": {}, "critical_errors": [], "recommendations": [], "citations": [],
                    "disclaimer": "LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç (blocking fallback)."
                }
                if raw_stream_text:
                    out["raw_stream"] = raw_stream_text
                return out

            parsed2 = safe_json_extract2(s)
            if isinstance(parsed2, dict) and parsed2:
                if raw_stream_text:
                    parsed2.setdefault("raw_stream", raw_stream_text)
                return parsed2

            # –¥–∞–∂–µ –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –æ—Ç–≤–µ—Ç –Ω–µ JSON ‚Üí –≤–µ—Ä–Ω—ë–º –∫–∞–∫ raw_block + raw_stream
            return {
                "critical_errors": [],
                "recommendations": [],
                "citations": [],
                "disclaimer": "LLM –≤–µ—Ä–Ω—É–ª –Ω–µ-JSON (blocking fallback).",
                "raw_block": s,
                **({"raw_stream": raw_stream_text} if raw_stream_text else {}),
            }

        except _requests.exceptions.ReadTimeout as e:
            out = {
                "critical_errors": [], "recommendations": [], "citations": [],
                "disclaimer": f"LLM timeout: {e} (blocking fallback)"
            }
            if raw_stream_text:
                out["raw_stream"] = raw_stream_text
            return out
        except Exception as e:
            out = {
                "critical_errors": [], "recommendations": [], "citations": [],
                "disclaimer": f"–û—à–∏–±–∫–∞ LLM ({type(e).__name__}): {e}"
            }
            if raw_stream_text:
                out["raw_stream"] = raw_stream_text
            return out

    except _requests.exceptions.ConnectTimeout:
        return {
            "critical_errors": [], "recommendations": [], "citations": [],
            "disclaimer": f"LLM timeout: —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ >{connect_timeout_s} c."
        }
    except Exception as e:
        return {
            "critical_errors": [], "recommendations": [], "citations": [],
            "disclaimer": f"–û—à–∏–±–∫–∞ LLM ({type(e).__name__}): {e}"
        }


# ================================
# API models
# ================================
class AnalyzeReq(BaseModel):
    case_text: str
    query: Optional[str] = None
    k: Optional[int] = Field(default=None)
    model: str = Field(default_factory=lambda: cfg("ollama", "model", default="llama3.1:8b"))
    ollama_url: Optional[str] = Field(default_factory=lambda: cfg("ollama", "base_url", default="http://ollama:11434"))

    if _P_V2:
        @field_validator("k", mode="before")
        def _coerce_k_v2(cls, v):
            if v in (None, "", "null"):
                return settings.RETR_TOP_K
            try:
                return int(v)
            except Exception:
                return settings.RETR_TOP_K
    else:
        @field_validator("k", pre=True)
        def _coerce_k_v1(cls, v):
            if v in (None, "", "null"):
                return settings.RETR_TOP_K
            try:
                return int(v)
            except Exception:
                return settings.RETR_TOP_K

# ================================
# Helpers
# ================================
def _resolve(name: str, default: str) -> str:
    return (os.getenv(name) or cfg(*name.lower().split("_"), default=None) or default)

# ================================
# Routes
# ================================
@app.get("/health")
def health():
    qdrant_url = settings.QDRANT_URL
    collection = settings.QDRANT_COLLECTION
    emb_backend = settings.EMB_BACKEND
    hf_model = settings.HF_MODEL
    device = settings.HF_DEVICE or "auto"
    return {
        "status": "ok",
        "app_env": os.getenv("APP_ENV", "dev"),
        "qdrant": qdrant_url,
        "qdrant_collection": collection,
        "llm_model": cfg("ollama", "model", default="llama3.1:8b"),
        "embed_backend": emb_backend,
        "embed_model": hf_model,
        "embed_device": device,
    }

@app.get("/debug/config")
def debug_config():
    return {
        "ollama": {
            "base_url": cfg_str("ollama", "base_url", default="http://ollama:11434"),
            "model": cfg_str("ollama", "model", default="llama3.1:8b"),
            "max_tokens": cfg_int("ollama", "max_tokens", default=2048),
            "timeout_s": cfg_int("ollama", "timeout_s", default=60),
            "temperature": cfg_float("ollama", "temperature", default=0.4),
            "top_p": cfg_float("ollama", "top_p", default=0.95),
            "num_ctx": cfg_int("ollama", "num_ctx", default=6144),
        },
        "qdrant": {
            "url": settings.QDRANT_URL,
            "collection": settings.QDRANT_COLLECTION,
        },
        "retrieval": {"k": settings.RETR_TOP_K},
        "chunking": {
            "child_w": cfg_int("chunking", "child_w", default=200),
            "child_overlap": cfg_int("chunking", "child_overlap", default=35),
            "parent_w": cfg_int("chunking", "parent_w", default=800),
        },
    }

@app.post("/config/reload")
def config_reload():
    global CONFIG
    CONFIG = load_config()
    try:
        settings.apply_env(force=True)
    except Exception:
        pass
    return {"status": "reloaded"}

def _compact_case_text(txt: str, target_chars: int = 1400) -> str:
    if not txt:
        return ""
    t = txt
    t = re.sub(r"[ \t]+", " ", t)
    t = re.sub(r"\n{3,}", "\n\n", t).strip()
    t = re.sub(r"\b(–æ—Ç—Ä–∏—Ü–∞–µ—Ç|–Ω–µ\s+–æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ|–Ω–µ\s+–Ω–∞—Ö–æ–¥–∏–ª—Å—è|–Ω–µ\s+–æ—Ç—è–≥–æ—â–µ–Ω)\b[.,;:\s]*", "–Ω–µ—Ç. ", t, flags=re.IGNORECASE)
    t = re.sub(r"\b(–±–µ–∑–±–æ–ª–µ–∑–Ω–µ–Ω–Ω–∞—è|–∫–æ–∂–∞ –æ–±—ã—á–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏|—É–º–µ—Ä–µ–Ω–Ω–æ –≤–ª–∞–∂–Ω–∞—è|—Å–≤–æ–±–æ–¥–Ω\w*|–ø–æ —Å—Ä–µ–¥–Ω–µ–π –ª–∏–Ω–∏–∏)\b[.,;:\s]*", "", t, flags=re.IGNORECASE)
    t = re.sub(r"[.;:,]\s*(?:[.;:,]\s*)+", ". ", t)
    t = re.sub(r"\s{2,}", " ", t)

    seen = set()
    out = []
    for sent in re.split(r"(?<=[.!?])\s+", t):
        s = sent.strip()
        key = re.sub(r"\W+", "", s.lower())
        if len(key) < 5:
            continue
        if key in seen:
            continue
        seen.add(key)
        out.append(s)
    t = " ".join(out)

    if len(t) > target_chars:
        cut = t[:target_chars]
        last_dot = cut.rfind(".")
        if last_dot > target_chars * 0.6:
            t = cut[:last_dot+1]
        else:
            t = cut

    return t.strip()
# ---- helpers: safe formatting for prompt templates ----
class _SafeDict(dict):
    def __missing__(self, key):
        # –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∫–∞–∫ –µ—Å—Ç—å
        return "{" + key + "}"

def safe_format(template: str, **kwargs) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É, –Ω–µ –ø–∞–¥–∞—è –Ω–∞ —á—É–∂–∏—Ö {—Å–∫–æ–±–∫–∞—Ö}.
    –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ {case_text} –∏ {ctx} –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∏–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã,
    –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏ —ç–∫—Ä–∞–Ω–∏—Ä—É—é—Ç—Å—è.
    """
    if not isinstance(template, str):
        return template
    # –≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä—è—á–µ–º –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
    t = template.replace("{case_text}", "<<<__CASE__>>>").replace("{ctx}", "<<<__CTX__>>>")
    # —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏
    t = t.replace("{", "{{").replace("}", "}}")
    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
    t = t.replace("<<<__CASE__>>>", "{case_text}").replace("<<<__CTX__>>>", "{ctx}")
    # —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ
    try:
        return t.format_map(_SafeDict(**kwargs))
    except Exception:
        # –Ω–∞ –∫—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π ‚Äì –ø–æ–¥—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è
        return t.format(case_text=kwargs.get("case_text", ""), ctx=kwargs.get("ctx", ""))

CODE_BLOCK_RE = re.compile(r"```[a-zA-Z0-9_+\-]*\s*([\s\S]*?)```", flags=re.DOTALL)

def strip_code_fences_strict(s: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π ```–±–ª–æ–∫``` –µ—Å–ª–∏ –æ–Ω —Ü–µ–ª–∏–∫–æ–º. –ò–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ –µ—Å—Ç—å."""
    if not s: return s
    m = CODE_BLOCK_RE.search(s)
    return m.group(1).strip() if m else s.strip()

def strip_code_fences_loose(s: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –¥–∞–∂–µ –ù–ï–ó–ê–ö–†–´–¢–´–ï –Ω–∞—á–∞–ª–∞ –∫–æ–¥–∞: '```json\\n...' ‚Üí —Ç–µ–∫—Å—Ç –±–µ–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏."""
    if not s: return s
    s = s.replace("\r", "")
    s = s.lstrip()
    if s.startswith("```"):
        p = s.find("\n")
        if p != -1:
            s = s[p+1:]
        else:
            s = ""  # –≤–µ—Å—å —Ç–µ–∫—Å—Ç –±—ã–ª –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π —Å ``` ‚Äî —É–±–∏—Ä–∞–µ–º
    # —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç–æ–≤—ã–µ ¬´—Å–ª—É—á–∞–π–Ω—ã–µ¬ª ```
    s = s.rstrip("`").rstrip()
    return s

def smart_trim(s: str, max_len: int = 1800) -> str:
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–±—Ä–µ–∑–∞–µ—Ç –ø–æ –∫–æ–Ω—Ü—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è/—Å—Ç—Ä–æ–∫–∏/—Å–ª–æ–≤–∞, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å –ø–æ—Å—Ä–µ–¥–∏ —Å–ª–æ–≤–∞."""
    if not s or len(s) <= max_len:
        return (s or "").strip()
    cut = s[:max_len]
    # 1) –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 200 —Å–∏–º–≤–æ–ª–∞—Ö
    tail = cut[-200:]
    off = max(tail.rfind(". "), tail.rfind("! "), tail.rfind("? "), tail.rfind("‚Ä¶ "))
    if off != -1:
        return (cut[:max_len-200 + off + 2]).rstrip()
    # 2) –∏–Ω–∞—á–µ –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏
    nl = cut.rfind("\n")
    if nl >= max_len - 200:
        return cut[:nl].rstrip()
    # 3) –∏–Ω–∞—á–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª
    sp = cut.rfind(" ")
    if sp >= max_len - 120:
        return cut[:sp].rstrip()
    return cut.rstrip()



# ================================
# UI
# ================================
UI_HTML = """<!doctype html><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–∞—á–∞ (MVP)</title>
<style>
body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;background:#f6f7fb;margin:0;color:#101828}
.wrap{max-width:1100px;margin:20px auto;padding:16px}
.card{background:#fff;border:1px solid #e5e7eb;border-radius:16px;box-shadow:0 1px 3px rgba(16,24,40,.08);padding:16px;margin-bottom:16px}
h1{font-size:20px;margin:0 0 8px}
h3{margin:0 0 6px}
h4{margin:12px 0 6px}
label{font-weight:600;font-size:14px;margin:6px 0;display:block}
input,select,textarea{width:100%;border:1px solid #d0d5dd;border-radius:10px;padding:10px;font-size:14px}
textarea{min-height:180px}
.row{display:grid;grid-template-columns:1fr 1fr;gap:12px}
.btn{background:#2563eb;color:#fff;border:none;border-radius:10px;padding:10px 14px;font-weight:600;cursor:pointer}
.btn:disabled{opacity:.6;cursor:not-allowed}
.badge{display:inline-block;border:1px solid #d0d5dd;border-radius:999px;padding:2px 8px;font-size:12px;margin-left:8px}
.mono{font-family:ui-monospace,Menlo,Consolas,monospace;font-size:12px}
.small{font-size:12px;color:#475467}
.err{color:#b91c1c}
.grid2{display:grid;grid-template-columns:1fr 1fr;gap:8px}
.help{font-size:12px;color:#667085;margin-top:4px}
.muted{color:#667085}
li{margin:6px 0}
.chk{display:flex;align-items:center;gap:8px;margin-top:6px}
</style>

<div class="wrap">
  <div class="card">
    <h1>
      AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–∞—á–∞ (MVP)
      <span id="score" class="badge">–æ—Ü–µ–Ω–∫–∞: ‚Äî</span>
      <span id="mode" class="badge" style="background:#eef2ff">—Ä–µ–∂–∏–º: –º–µ–¥</span>
    </h1>
    <div class="small">API: <span id="api"></span></div>
    <div class="small" id="role" style="margin-top:4px"></div>
  </div>

  <div class="card">
    <label>–¢–µ–∫—Å—Ç –∫–µ–π—Å–∞</label>
    <textarea id="case" placeholder="–í—Å—Ç–∞–≤—å—Ç–µ –∫–µ–π—Å: –∂–∞–ª–æ–±—ã, –∞–Ω–∞–º–Ω–µ–∑, –¥–∏–∞–≥–Ω–æ–∑, –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è..."></textarea>

    <div class="row">
      <div>
        <label class="chk" title="–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ ‚Äî –æ—Ç–≤–µ—Ç–∏—Ç —Å–≤–æ–±–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ (—Ü–∏—Ç–∞—Ç –Ω–µ –±—É–¥–µ—Ç).">
          <input type="checkbox" id="use_free">
          <span class="small">–°–≤–æ–±–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å</span>
        </label>

        <label>–ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–µ–∂–∏–º–∞ ¬´–º–µ–¥¬ª)</label>
        <input id="query" placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä: –ò–ë–° –ª–µ—á–µ–Ω–∏–µ...">
        <div class="help">–í —Ä–µ–∂–∏–º–µ ¬´—Å–≤–æ–±–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å¬ª –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.</div>
      </div>

      <div>
        <label>–ú–æ–¥–µ–ª—å / K (—Ç–æ–ª—å–∫–æ –¥–ª—è ¬´–º–µ–¥¬ª)</label>
        <div class="row" style="grid-template-columns:2fr 1fr;gap:8px">
          <select id="model"></select>
          <input id="k" type="number" value="" min="0" max="20" placeholder="–ø–æ —É–º–æ–ª—á.">
        </div>
        <div class="help">–û—Å—Ç–∞–≤—å—Ç–µ K –ø—É—Å—Ç—ã–º ‚Äî –≤–æ–∑—å–º—ë—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å–µ—Ä–≤–µ—Ä–∞</div>
      </div>
    </div>

    <div style="margin-top:10px;display:flex;gap:8px;align-items:center;flex-wrap:wrap">
      <button id="run" class="btn">–û—Ç–ø—Ä–∞–≤–∏—Ç—å</button>
      <button id="reindex" class="btn" style="background:#059669">üîÑ –û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É</button>
      <span id="busy" class="small" style="display:none">‚è≥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è‚Ä¶</span>
      <span id="error" class="small err"></span>
    </div>
  </div>

  <div class="card">
    <h3>–†–µ–∑—É–ª—å—Ç–∞—Ç</h3>
    <div class="grid2" id="subs"></div>

    <div id="crit_wrap">
      <h4>–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏</h4>
      <ul id="crit"></ul>
    </div>

    <div id="recs_wrap">
      <h4>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h4>
      <ul id="recs"></ul>
    </div>

    <h4>–°–≤–æ–±–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç</h4>
    <div id="free" style="white-space:pre-wrap;border:1px dashed #e5e7eb;border-radius:10px;padding:10px;background:#fafafa;display:none"></div>

    <div id="cits_wrap">
      <h4>–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (—Ü–∏—Ç–∞—Ç—ã)</h4>
      <ul id="cits"></ul>
    </div>

    <div id="disc" class="small muted" style="margin-top:8px"></div>

    <details style="margin-top:8px">
      <summary class="small">–°—ã—Ä–æ–π JSON</summary>
      <pre id="raw" class="mono"></pre>
    </details>
  </div>
</div>

<script>
const API = window.location.origin;
document.getElementById('api').textContent = API;

const el = id => document.getElementById(id);
const show = (n,on) => n.style.display = on ? '' : 'none';

function colorForScore(s){
  if (typeof s !== 'number') return '';
  if (s >= 85) return '#dcfce7';
  if (s >= 65) return '#fef9c3';
  return '#fee2e2';
}

const labelMap = {
  "diagnosis": "–î–∏–∞–≥–Ω–æ–∑",
  "diagnosis_match": "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–∏–∞–≥–Ω–æ–∑—É",
  "therapy": "–¢–µ—Ä–∞–ø–∏—è",
  "med_choice": "–í—ã–±–æ—Ä –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞",
  "dosage": "–î–æ–∑–∏—Ä–æ–≤–∫–∞",
  "dosing": "–î–æ–∑–∏—Ä–æ–≤–∫–∞",
  "interactions": "–õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è",
  "contraindications": "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è",
  "monitoring": "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
  "evidence": "–î–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
};

function renderList(ul, items, renderItem, emptyText="–ù–µ—Ç"){
  ul.innerHTML = '';
  if (!Array.isArray(items) || items.length === 0){
    const li=document.createElement('li');
    li.className='muted';
    li.textContent = emptyText;
    ul.appendChild(li);
    return;
  }
  items.forEach(it => {
    const li=document.createElement('li');
    renderItem(li, it);
    ul.appendChild(li);
  });
}

function normalizeRecs(R){
  const arr = Array.isArray(R) ? R : (
    typeof R === 'string' && R.trim() ? [R.trim()] :
    (R && typeof R === 'object') ? [R] : []
  );
  return arr.filter(x => {
    if (typeof x === 'string') return x.trim().length > 0;
    if (x && typeof x === 'object') {
      const wt = (x.what_to_change || '').trim();
      const rn = (x.rationale || '').trim();
      return wt.length > 0 || rn.length > 0;
    }
    return !!x;
  });
}

function renderResult(r){
  const metaMode = (r.meta && r.meta.mode) ? String(r.meta.mode) : null;
  const modeBadge = el('mode');
  const isFree = metaMode === 'free';

  // –±–µ–π–¥–∂ —Ä–µ–∂–∏–º–∞
  modeBadge.textContent = '—Ä–µ–∂–∏–º: ' + (isFree ? '—Å–≤–æ–±–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å' : '–º–µ–¥');
  modeBadge.style.background = isFree ? '#e0f2fe' : '#eef2ff';

  // –±–µ–π–¥–∂ –æ—Ü–µ–Ω–∫–∏ (–≤ free –Ω–µ –∫—Ä–∞—Å–∏–º)
  const scBadge = el('score');
  const sc = (typeof r.score === 'number') ? r.score : '‚Äî';
  scBadge.textContent = '–æ—Ü–µ–Ω–∫–∞: ' + sc;
  scBadge.style.background = isFree ? '' : colorForScore(r.score);

  // —Ä–æ–ª—å
  el('role').textContent = (r.meta && r.meta.role) ? ('–†–æ–ª—å: ' + String(r.meta.role)) : '';

  // —Å–≤–æ–±–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç:
  //  - –≤ FREE –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û free_text
  //  - –≤ MED –ø–æ–∫–∞–∑—ã–≤–∞–µ–º free_text, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å (–∏–Ω–∞—á–µ –ø—Ä—è—á–µ–º)
  const freeBox = el('free');
  const freeTxt = (r.free_text || '').toString().trim();
  if (isFree) {
    if (freeTxt) { freeBox.textContent = freeTxt; show(freeBox, true); }
    else { freeBox.textContent = ''; show(freeBox, false); }
  } else {
    if (freeTxt) { freeBox.textContent = freeTxt; show(freeBox, true); }
    else { freeBox.textContent = ''; show(freeBox, false); }
  }

  // —Å–∞–±—Å–∫–æ—Ä–∏–Ω–≥
  const subs = el('subs');
  subs.innerHTML = '';
  const entries = Object.entries(r.subscores || {});
  if (entries.length === 0) subs.style.display = 'none';
  else {
    subs.style.display = 'grid';
    entries.forEach(([k,v])=>{
      const d=document.createElement('div'); d.className='card'; d.style.margin=0;
      d.innerHTML=`<div class="small">${labelMap[k] || k}</div><div style="font-weight:700">${v??'‚Äî'}</div>`;
      subs.appendChild(d);
    });
  }

  // –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
  renderList(el('crit'), r.critical_errors, (li,x)=>{
    const typ = (x && x.type) ? String(x.type) : '–û—à–∏–±–∫–∞';
    const exp = (x && x.explain) ? String(x.explain) : '';
    li.textContent = exp ? (typ + ': ' + exp) : typ;
  });

  // —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
  renderList(el('recs'), normalizeRecs(r.recommendations), (li,x)=>{
    if (typeof x === 'string') li.textContent = x;
    else if (x && typeof x === 'object') {
      const wt = (x.what_to_change || '').trim();
      const rn = (x.rationale || '').trim();
      li.textContent = wt && rn ? `${wt} ‚Äî ${rn}` : (wt || rn || JSON.stringify(x));
    } else li.textContent = String(x);
  });

  // —Ü–∏—Ç–∞—Ç—ã: –≤ FREE –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–∫—Ä—ã–≤–∞–µ–º; –≤ MED ‚Äî –ø–æ –Ω–∞–ª–∏—á–∏—é
  const citsWrap = el('cits_wrap');
  const cits = el('cits');
  if (isFree) {
    citsWrap.style.display = 'none';
    cits.innerHTML = '';
  } else {
    const hasCits = Array.isArray(r.citations) && r.citations.length > 0;
    if (hasCits) {
      citsWrap.style.display = '';
      renderList(cits, r.citations, (li,x)=>{ li.textContent = String(x); });
    } else {
      citsWrap.style.display = 'none';
      cits.innerHTML = '';
    }
  }

  // –¥–∏—Å–∫–ª–µ–π–º–µ—Ä ‚Äî –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ FREE
  el('disc').textContent = isFree ? '' : (r.disclaimer ? String(r.disclaimer) : '');
  el('raw').textContent = JSON.stringify(r,null,2);
}

function prettyModelName(id){
  if (id === 'llama3.1:8b')      return 'Llama 3.1 (8B)';
  if (id === 'llama3.1:70b')     return 'Llama 3.1 (70B)';
  if (id === 'deepseek-r1:32b')  return 'DeepSeek R1 (32B)';
  return id;
}

function updateModeUI(){
  const isFree = el('use_free').checked;
  el('query').disabled = isFree;
  el('model').disabled = isFree;
  el('k').disabled = isFree;

  const modeBadge = el('mode');
  modeBadge.textContent = '—Ä–µ–∂–∏–º: ' + (isFree ? '—Å–≤–æ–±–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å' : '–º–µ–¥');
  modeBadge.style.background = isFree ? '#e0f2fe' : '#eef2ff';
}

async function fillModels(){
  try{
    const res = await fetch(API + '/runtime/models');
    const m = await res.json();
    const sel = el('model');
    sel.innerHTML = '';
    (m.allowed || []).forEach(id => {
      const opt = document.createElement('option');
      opt.value = id;
      opt.textContent = prettyModelName(id);
      if (id === m.active) opt.selected = true;
      sel.appendChild(opt);
    });
  }catch(e){
    console.error('models fetch failed', e);
    const sel = el('model');
    ['llama3.1:8b','llama3.1:70b','deepseek-r1:32b'].forEach(id=>{
      const opt = document.createElement('option');
      opt.value = id; opt.textContent = prettyModelName(id);
      sel.appendChild(opt);
    });
  } finally {
    updateModeUI();
  }
}

async function run(){
  el('error').textContent = '';
  el('busy').textContent = '‚è≥ –∞–Ω–∞–ª–∏–∑‚Ä¶';
  show(el('busy'), true);
  el('run').disabled = true;

  try{
    const body = {
      case_text: (el('case').value || '').trim(),
      query:     (el('query').value || '').trim() || null,
      model:     el('model').value || 'llama3.1:8b',
      use_free:  !!el('use_free').checked
    };

    const kRaw = (el('k').value || '').trim();
    if (kRaw !== '') {
      const kParsed = parseInt(kRaw, 10);
      if (Number.isFinite(kParsed)) body.k = kParsed;
    }

    const res = await fetch(API + '/analyze', {
      method:'POST',
      headers:{'Content-Type':'application/json'},
      body: JSON.stringify(body)
    });

    const txt = await res.text();
    let data;
    try { data = JSON.parse(txt); }
    catch(e){ throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å JSON –æ—Ç–≤–µ—Ç–∞: ' + txt.slice(0,200)); }

    const payload = (data && data.result) ? data.result : data;
    renderResult(payload || {});
  }catch(e){
    el('error').textContent = '–û—à–∏–±–∫–∞: ' + (e?.message || e);
  }finally{
    show(el('busy'), false);
    el('run').disabled = false;
  }
}

el('use_free').addEventListener('change', updateModeUI);
el('run').onclick = run;

el('reindex').onclick = async () => {
  el('error').textContent = '';
  el('busy').textContent = 'üîÑ –∑–∞–ø—É—Å–∫ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏‚Ä¶';
  show(el('busy'), true);
  try {
    const res = await fetch(API + '/reindex', { method: 'POST' });
    const data = await res.json();
    el('error').textContent = data.message || '–ó–∞–ø—É—â–µ–Ω–æ.';
  } catch(e) {
    el('error').textContent = '–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: ' + (e?.message || e);
  } finally {
    show(el('busy'), false);
  }
};

async function checkReindexStatus() {
  try {
    const res = await fetch(API + '/reindex/status');
    const data = await res.json();
    const msg = data.message || '';
    const state = data.state;
    if (state === 'running') {
      el('busy').textContent = 'üîÑ ' + msg;
      show(el('busy'), true);
    } else if (state === 'done') {
      el('busy').textContent = '‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞';
      setTimeout(() => show(el('busy'), false), 4000);
    } else if (state === 'error') {
      el('busy').textContent = '‚ùå ' + msg;
    }
  } catch(e) { console.error(e); }
}

setInterval(checkReindexStatus, 60000);
fillModels();
</script>
"""



@app.get("/", response_class=HTMLResponse)
def ui_root():
    return HTMLResponse(UI_HTML)

# ================================
# Reindex
# ================================
index_status = {"state": "idle", "message": "–û–∂–∏–¥–∞–Ω–∏–µ"}

@app.get("/runtime/defaults")
def runtime_defaults():
    return {
        "RETR_TOP_K": settings.RETR_TOP_K,
        "RERANKER_ENABLED": settings.RERANKER_ENABLED,
        "RERANK_TOP_K": settings.RERANK_TOP_K,
        "HF_MODEL": settings.HF_MODEL,
        "LLM_ACTIVE": settings.LLM_ACTIVE,
        "LLM_ALLOWED": settings.LLM_ALLOWED,
        "LLM_PRESETS": settings.LLM_PRESETS,
        "LLM_BASE_URL": settings.LLM_BASE_URL,
    }

@app.get("/runtime/models")
def runtime_models():
    allowed = llm_get_allowed()
    labels = llm_get_labels()
    return {
        "active": llm_get_active(),
        "allowed": allowed,
        "labels": {m: labels.get(m, m) for m in allowed},
        "presets": {m: llm_get_preset(m) for m in allowed},
    }

@app.get("/reindex/status")
def reindex_status():
    return index_status

def run_reindex(*, full: bool = False):
    import os as _os
    import time as _time
    import socket as _socket
    import subprocess as _subprocess
    from pathlib import Path

    try:
        settings.apply_env(force=True)
    except Exception:
        pass

    global index_status

    base = ROOT
    raw_dir = str(base / "raw_docs")
    data_dir = str(base / "data")
    ingest_py = str(base / "ingest_from_raw.py")
    build_bm25_py = str(base / "build_bm25.py")
    chunk_and_index_py = str(base / "chunk_and_index.py")

    def _nz(val, default):
        s = (val or "").strip() if isinstance(val, str) else val
        return s if s not in (None, "", "None") else default

    def _as_int(val, fallback: int) -> int:
        try:
            if isinstance(val, (int, float)) and not isinstance(val, bool):
                return int(val)
            if isinstance(val, str) and val.strip() and val.strip().lower() != "none":
                return int(float(val.strip()))
        except Exception:
            pass
        return int(fallback)

    def _normalize_qdrant_url(url: str) -> str:
        try:
            if "qdrant:" in url:
                _socket.gethostbyname("qdrant")
        except Exception:
            return "http://localhost:7779"
        return url

    STAMP_BM25 = Path("index/.bm25_last_build")

    def _latest_pages_mtime() -> float:
        pages = list(Path("data").glob("*.pages.jsonl"))
        return max((p.stat().st_mtime for p in pages), default=0.0)

    def _bm25_needs_rebuild() -> bool:
        last_pages = _latest_pages_mtime()
        if last_pages == 0.0:
            return False
        if not STAMP_BM25.exists():
            return True
        return last_pages > STAMP_BM25.stat().st_mtime

    def _touch_bm25_stamp():
        STAMP_BM25.parent.mkdir(parents=True, exist_ok=True)
        STAMP_BM25.write_text(str(_time.time()), encoding="utf-8")

    try:
        env = _os.environ.copy()
        env["QDRANT__PREFER_GRPC"] = "false"

        index_status.update({"state": "running", "message": "üìÑ –®–∞–≥ 1: –ø–∞—Ä—Å–∏–Ω–≥ RAW ‚Üí JSONL (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ)..."})
        print("‚ñ∂Ô∏è ingest_from_raw.py ...")

        cmd_ingest = ["python", ingest_py, "--input-dir", raw_dir, "--out-dir", data_dir]

        man = Path(data_dir) / "manifest.json"
        try:
            first_run = not man.exists() or not (json.loads(man.read_text(encoding="utf-8") or "{}").get("docs") or [])
        except Exception:
            first_run = True

        if full or first_run:
            cmd_ingest.append("--force")

        _subprocess.run(cmd_ingest, check=True, env=env)

        qdrant_url = _normalize_qdrant_url(
            _nz(_os.getenv("QDRANT_URL") or cfg("qdrant", "url", default=settings.QDRANT_URL),
                settings.QDRANT_URL)
        )
        collection  = _nz(_os.getenv("QDRANT_COLLECTION") or cfg("qdrant", "collection", default=settings.QDRANT_COLLECTION),
                          settings.QDRANT_COLLECTION)
        emb_backend = _nz(_os.getenv("EMB_BACKEND") or cfg("embedding", "backend", default=settings.EMB_BACKEND), "hf")
        hf_model    = _nz(_os.getenv("HF_MODEL") or cfg("embedding", "model", default=settings.HF_MODEL), settings.HF_MODEL)

        child_w       = _as_int(_os.getenv("CHILD_W"),       cfg("chunking", "child_w",       default=200))
        child_overlap = _as_int(_os.getenv("CHILD_OVERLAP"), cfg("chunking", "child_overlap", default=35))
        parent_w      = _as_int(_os.getenv("PARENT_W"),      cfg("chunking", "parent_w",      default=800))

        bm25_child_w  = _as_int(_os.getenv("BM25_CHILD_W"),         _as_int(_os.getenv("CHILD_W"), 200))
        bm25_overlap  = _as_int(_os.getenv("BM25_CHILD_OVERLAP"),   _as_int(_os.getenv("CHILD_OVERLAP"), 40))
        bm25_lang     = _nz(_os.getenv("BM25_LANGUAGE"),            "ru")

        print(
            "üîß RESOLVED ‚Üí "
            f"QDRANT_URL={qdrant_url}  QDRANT_COLLECTION={collection}  "
            f"EMB_BACKEND={emb_backend}  HF_MODEL={hf_model}  "
            f"child_w={child_w} child_overlap={child_overlap} parent_w={parent_w}  "
            f"[BM25 child_w={bm25_child_w} overlap={bm25_overlap} lang={bm25_lang}]"
        )

        if full or _bm25_needs_rebuild():
            index_status["message"] = "üìö –®–∞–≥ 2: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ BM25 –∏–Ω–¥–µ–∫—Å–∞..."
            print("‚ñ∂Ô∏è build_bm25.py ...")
            _subprocess.run(
                [
                    "python", build_bm25_py,
                    "--pages-glob", "data/*.pages.jsonl",
                    "--out-json",   "index/bm25_json",
                    "--index-dir",  "index/bm25_idx",
                    "--child-w",    str(bm25_child_w),
                    "--child-overlap", str(bm25_overlap),
                    "--language",   bm25_lang,
                ],
                check=True, env=env
            )
            _touch_bm25_stamp()
        else:
            index_status["message"] = "‚è≠Ô∏è  –®–∞–≥ 2 –ø—Ä–æ–ø—É—â–µ–Ω: –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è BM25 –Ω–µ—Ç"
            print(index_status["message"])

        # --- –®–∞–≥ 3: Dense ‚Üí Qdrant ---
        index_status["message"] = "üß† –®–∞–≥ 3: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant (dense)..."

        emb_batch = str(_as_int(_os.getenv("EMB_BATCH"), 128))  # —á–∏—Ç–∞–µ–º –∏–∑ ENV, –¥–µ—Ñ–æ–ª—Ç 128

        cmd_qdr = [
            "python", chunk_and_index_py,
            "--pages-glob",    "data/*.pages.jsonl",
            "--collection",    collection,
            "--qdrant-url",    qdrant_url,
            "--emb-backend",   emb_backend,
            "--hf-model",      hf_model,
            "--batch",         emb_batch,          # <‚îÄ‚îÄ –≤–æ—Ç –æ–Ω–æ
            "--child-w",       str(child_w),
            "--child-overlap", str(child_overlap),
            "--parent-w",      str(parent_w),
        ]
        cmd_qdr.append("--recreate" if full else "--only-new")

        print("‚ñ∂Ô∏è CMD:", " ".join(cmd_qdr))
        _subprocess.run(cmd_qdr, check=True, env=env)

        index_status.update({"state": "done", "message": "‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞."})
        print("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    except _subprocess.CalledProcessError as e:
        index_status.update({"state": "error", "message": f"‚ùå –ü—Ä–æ—Ü–µ—Å—Å —É–ø–∞–ª: {e}"})
        print(index_status["message"])
    except Exception as e:
        index_status.update({"state": "error", "message": f"‚ùå –û—à–∏–±–∫–∞: {e}"})
        print(index_status["message"])

@app.post("/reindex")
def reindex_ep(full: bool = False):
    threading.Thread(target=run_reindex, kwargs={"full": bool(full)}, daemon=True).start()
    return {"status": "started", "message": "–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞", "full": bool(full)}
