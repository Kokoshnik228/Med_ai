#!/usr/bin/env python3
"""
RAW (PDF/DOCX/TXT) -> data/*.pages.jsonl + data/manifest.json

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ --input-dir (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é raw_docs/).
- PDF: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ OCR (tesseract –∏–ª–∏ easyocr).
- DOCX/TXT: –Ω–∞—Ä–µ–∑–∫–∞ –Ω–∞ ¬´–ø—Å–µ–≤–¥–æ-—Å—Ç—Ä–∞–Ω–∏—Ü—ã¬ª —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1800 —Å–∏–º–≤–æ–ª–æ–≤),
  —á—Ç–æ–±—ã down-stream (BM25/Qdrant/—Ü–∏—Ç–∞—Ç—ã) —Ä–∞–±–æ—Ç–∞–ª –æ–¥–∏–Ω–∞–∫–æ–≤–æ —Å PDF.
- –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ—Å—Ç—å: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–æ SHA1), –µ—Å–ª–∏ –ù–ï —É–∫–∞–∑–∞–Ω --force.
- EasyOCR: ¬´—Ç—ë–ø–ª—ã–π —Å—Ç–∞—Ä—Ç¬ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –æ–¥–∏–Ω —Ä–∞–∑; –≤ –≤–æ—Ä–∫–µ—Ä–∞—Ö —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ.
- GPU-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è EasyOCR: –º–æ–∂–Ω–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (--ocr-gpu cuda|cpu|auto),
  –ø—É—Ç—å –∫ –∫—ç—à—É –º–æ–¥–µ–ª–µ–π –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (--easyocr-allow-downloads).
- ‚úÇÔ∏è –ê–ù–¢–ò-–õ–ò–¢–ï–†–ê–¢–£–†–ê: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—Ä–µ–∑–∞–µ–º —Ä–∞–∑–¥–µ–ª—ã ¬´–°–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã / References¬ª.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ app):
  pip install chardet pymupdf pillow python-docx
  # –¥–ª—è OCR (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
  apt-get install -y tesseract-ocr tesseract-ocr-eng tesseract-ocr-rus
  pip install easyocr opencv-python-headless
"""

from __future__ import annotations
import argparse
import json
import sys
import os
import re
import hashlib
from pathlib import Path
from typing import Dict, Any, List
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
from time import perf_counter

import numpy as np
import chardet

# ---------- –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã ----------
try:
    import fitz  # PyMuPDF
except Exception as e:
    print("[ERR] –¢—Ä–µ–±—É–µ—Ç—Å—è PyMuPDF: pip install pymupdf", file=sys.stderr, flush=True)
    raise

# python-docx==1.1.2
try:
    from docx import Document
except Exception:
    Document = None  # –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –Ω–∏–∂–µ

try:
    import pytesseract
    from PIL import Image
    TESS_AVAILABLE = True
except Exception:
    from PIL import Image  # Pillow –≤—Å—ë —Ä–∞–≤–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    TESS_AVAILABLE = False

try:
    import easyocr
    EASY_AVAILABLE = True
except Exception:
    EASY_AVAILABLE = False

# OpenCV (–ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è OCR)
try:
    import cv2
    CV_AVAILABLE = True
except Exception:
    CV_AVAILABLE = False

# Torch –¥–ª—è GPU-–∏–Ω—Ñ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ; –Ω–µ –ø–∞–¥–∞–µ–º, –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
try:
    import torch
    _TORCH_OK = True
except Exception:
    torch = None
    _TORCH_OK = False


# ================== –£—Ç–∏–ª–∏—Ç—ã ==================

def file_sha1(p: Path) -> str:
    h = hashlib.sha1()
    with p.open("rb") as f:
        for chunk in iter(lambda: f.read(1 << 20), b""):
            h.update(chunk)
    return h.hexdigest()


def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def detect_text_file(path: Path) -> str:
    data = path.read_bytes()
    enc = chardet.detect(data).get("encoding") or "utf-8"
    try:
        return data.decode(enc, errors="ignore")
    except Exception:
        return data.decode("utf-8", errors="ignore")


def pixmap_to_pil(pix: "fitz.Pixmap") -> "Image.Image":
    try:
        needs_colorspace_convert = getattr(pix.colorspace, "n", 3) != 3  # –Ω–µ RGB
    except Exception:
        needs_colorspace_convert = False
    if pix.alpha or needs_colorspace_convert:
        pix = fitz.Pixmap(fitz.csRGB, pix)
    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
    return img


# --- —Ç–µ–∫—Å—Ç–æ–≤–∞—è —á–∏—Å—Ç–∫–∞ –¥–ª—è OCR/–ø–∞—Ä—Å–µ—Ä–æ–≤ ---
_LATIN_TO_CYR = str.maketrans({
    "A":"–ê","a":"–∞","B":"–í","E":"–ï","e":"–µ","K":"–ö","k":"–∫","M":"–ú","H":"–ù","O":"–û","o":"–æ",
    "P":"–†","p":"—Ä","C":"–°","c":"—Å","T":"–¢","X":"–•","x":"—Ö","Y":"–£","y":"—É"
})

def clean_text(text: str) -> str:
    t = (text or "").replace("\r", "")
    t = re.sub(r"-\n", "", t)                                # —É–±—Ä–∞—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã —Å–æ –∑–Ω–∞–∫–æ–º –¥–µ—Ñ–∏—Å–∞
    t = t.replace("\n\n", "<<<PARA>>>").replace("\n", " ").replace("<<<PARA>>>", "\n\n")
    t = re.sub(r"[ \t]+", " ", t)                            # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã
    t = t.translate(_LATIN_TO_CYR)                           # —á–∞—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã –ª–∞—Ç–∏–Ω–∏—Ü—ã –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—É
    return t.strip()

# --- –¥–µ—Ç–µ–∫—Ç–æ—Ä ¬´–°–ø–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã¬ª / References ---
REFS_HDR_RE = re.compile(
    r'^\s*(?:'
    r'—Å–ø–∏—Å[–æo]–∫\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä[–∞—ã]|–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä[–∞—ã]|–∏—Å—Ç–æ—á–Ω–∏–∫–∏|'
    r'–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω[–∞-—è—ë]+\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä[–∞—ã]|'
    r'references?|bibliograph\w*'
    r')\s*[:\-‚Äì‚Äî]?\s*$',
    re.IGNORECASE | re.MULTILINE
)

def strip_tail_references(text: str) -> tuple[str, bool]:
    """
    –ù–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏ –∏ –æ–±—Ä–µ–∑–∞—Ç—å –≤—Å—ë, —á—Ç–æ –∏–¥—ë—Ç –ø–æ—Å–ª–µ –Ω–µ–≥–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–Ω–æ–≤—ã–π_—Ç–µ–∫—Å—Ç, –±—ã–ª–æ_–ª–∏_–æ–±—Ä–µ–∑–∞–Ω–∏–µ).
    """
    if not text:
        return text, False
    m = REFS_HDR_RE.search(text)
    if not m:
        return text, False
    return text[:m.start()].rstrip(), True


def split_text_to_pages(full_text: str, page_size_chars: int = 1800) -> List[Dict[str, Any]]:
    """–ù–∞—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ ¬´–ø—Å–µ–≤–¥–æ-—Å—Ç—Ä–∞–Ω–∏—Ü—ã¬ª –ø–æ —Å–∏–º–≤–æ–ª–∞–º, —Å—Ç–∞—Ä–∞—è—Å—å —É–≤–∞–∂–∞—Ç—å –∞–±–∑–∞—Ü—ã."""
    text = clean_text(full_text)
    # –ø–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–µ–∑–∞—Ç—å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—É –∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤/–¥–æ–∫—Å–æ–≤
    text, _ = strip_tail_references(text)

    if not text:
        return [{"page": 1, "text": ""}]

    parts: List[str] = []
    buf = []
    cur_len = 0
    # –≥—Ä—É–±–æ –ø–æ –∞–±–∑–∞—Ü–∞–º/–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
    tokens = re.split(r"(\n\n|[.!?]\s+)", text)
    for t in tokens:
        if t is None:
            continue
        if cur_len + len(t) > page_size_chars and buf:
            parts.append("".join(buf).strip())
            buf, cur_len = [t], len(t)
        else:
            buf.append(t)
            cur_len += len(t)
    if buf:
        parts.append("".join(buf).strip())

    pages: List[Dict[str, Any]] = []
    for i, chunk in enumerate(parts, start=1):
        pages.append({"page": i, "text": chunk})

    return pages or [{"page": 1, "text": text[:page_size_chars]}]


# ================== DOCX ==================

def extract_docx_text(path: Path) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ DOCX (–∞–±–∑–∞—Ü—ã + —Ç–∞–±–ª–∏—Ü—ã)."""
    if Document is None:
        print("[ERR] python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–æ–±–∞–≤—å `python-docx` –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.", file=sys.stderr, flush=True)
        return ""
    try:
        doc = Document(str(path))
    except Exception as e:
        print(f"[ERR] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å DOCX {path.name}: {e}", file=sys.stderr, flush=True)
        return ""

    parts: List[str] = []
    # –∞–±–∑–∞—Ü—ã
    for p in doc.paragraphs:
        t = (p.text or "").strip()
        if t:
            parts.append(t)
    # —Ç–∞–±–ª–∏—Ü—ã
    for table in doc.tables:
        for row in table.rows:
            cells = [ (c.text or "").strip() for c in row.cells ]
            line = " | ".join([c for c in cells if c])
            if line:
                parts.append(line)

    return "\n".join(parts).strip()


def ingest_docx(path: Path, page_size_chars: int = 1800) -> List[Dict[str, Any]]:
    """DOCX -> —Å–ø–∏—Å–æ–∫ {page, text} (–∫–∞–∫ —É PDF/TXT)."""
    raw = extract_docx_text(path)
    if not raw:
        return [{"page": 1, "text": ""}]
    # ‚úÇÔ∏è –æ–±—Ä–µ–∑–∞–µ–º –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—É –¥–æ –Ω–∞—Ä–µ–∑–∫–∏
    raw, _ = strip_tail_references(raw)
    return split_text_to_pages(raw, page_size_chars=page_size_chars)


# ================== OCR Backends ==================

def ocr_page_tesseract(img_pil: "Image.Image", lang: str) -> str:
    if not TESS_AVAILABLE:
        return ""
    # NB: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–¥—ã, —á—Ç–æ–±—ã –Ω–µ –¥—É—à–∏—Ç—å —Å–∏—Å—Ç–µ–º—É
    os.environ.setdefault("OMP_NUM_THREADS", "1")
    os.environ.setdefault("OPENBLAS_NUM_THREADS", "1")
    cfg = "--oem 1 --psm 6"
    return (pytesseract.image_to_string(img_pil, lang=lang, config=cfg) or "").strip()


def ocr_page_easyocr(img_pil: "Image.Image", reader) -> str:
    if reader is None:
        return ""
    arr = np.array(img_pil.convert("RGB"))
    res = reader.readtext(arr, detail=0, paragraph=True)
    return "\n".join([x.strip() for x in res if x]).strip()


def preprocess_pil(img_pil: "Image.Image") -> "Image.Image":
    """–õ—ë–≥–∫–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è OCR (–µ—Å–ª–∏ –µ—Å—Ç—å OpenCV)."""
    if not CV_AVAILABLE:
        return img_pil
    img = np.array(img_pil.convert("L"))  # grayscale
    # CLAHE (–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã)
    try:
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        img = clahe.apply(img)
    except Exception:
        pass
    # —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
    img = cv2.fastNlMeansDenoising(img, h=10)
    # –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                cv2.THRESH_BINARY, 35, 15)
    return Image.fromarray(img)


# ================== –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ==================

def ingest_pdf(
    pdf_path: Path,
    *,
    ocr_mode: str,            # "auto"|"always"|"never"
    ocr_backend: str,         # "tesseract"|"easyocr"
    ocr_lang: str,
    dpi: int,
    min_chars: int,
    verbose: bool,
    easy_reader=None
) -> List[Dict[str, Any]]:

    pages: List[Dict[str, Any]] = []
    try:
        doc = fitz.open(pdf_path)
    except Exception as e:
        print(f"[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å PDF {pdf_path.name}: {e}", file=sys.stderr, flush=True)
        return pages

    # –∫–∞–∫ —Ç–æ–ª—å–∫–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ ¬´–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞/References¬ª ‚Äî –æ–±—Ä–µ–∂–µ–º –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏–º—Å—è
    for i, page in enumerate(doc, start=1):
        txt = (page.get_text("text") or "").strip()

        # —Ä–µ—à–∞–µ–º, –¥–µ–ª–∞—Ç—å –ª–∏ OCR
        if ocr_mode == "always":
            do_ocr = True
        elif ocr_mode == "auto":
            do_ocr = (len(txt) < min_chars)
        else:  # "never"
            do_ocr = False

        # —Å–∞–º OCR (–í–ù–ï –≤–µ—Ç–∫–∏ "never")
        if do_ocr:
            if ocr_backend == "tesseract":
                zoom = dpi / 72.0
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat, alpha=False)
                img_pil = pixmap_to_pil(pix)

                img_pil = preprocess_pil(img_pil)
                txt_ocr = ocr_page_tesseract(img_pil, ocr_lang)

            elif ocr_backend == "easyocr":
                pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0), alpha=False)
                img_pil = pixmap_to_pil(pix)

                img_pil = preprocess_pil(img_pil)
                txt_ocr = ocr_page_easyocr(img_pil, easy_reader)

            else:
                txt_ocr = ""

            if len(txt_ocr) > len(txt):
                txt = txt_ocr
                if verbose:
                    print(f"[OCR-{ocr_backend}] {pdf_path.name} p.{i}: len={len(txt)}", flush=True)
            elif verbose and ocr_mode != "never" and txt_ocr:
                print(f"[OCR-{ocr_backend}] {pdf_path.name} p.{i}: OCR –Ω–µ —É–ª—É—á—à–∏–ª —Ç–µ–∫—Å—Ç (len={len(txt)})", flush=True)

        # ‚úÇÔ∏è —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ–±—Ä–µ–∑–∞—Ç—å –¥–æ —á–∏—Å—Ç–∫–∏
        if txt:
            txt_cut, cut0 = strip_tail_references(txt)
            if cut0:
                txt = txt_cut

        if txt:
            txt = clean_text(txt)

        # ‚úÇÔ∏è –µ—â—ë —Ä–∞–∑ –ø—Ä–æ–±—É–µ–º –ø–æ—Å–ª–µ clean_text (–Ω–∞ —Å–ª—É—á–∞–π OCR-¬´–∫–∞—à–∏¬ª –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ)
        if txt:
            txt_cut2, cut1 = strip_tail_references(txt)
            if cut1:
                txt = txt_cut2

        pages.append({"page": i, "text": txt})

        # –µ—Å–ª–∏ –±—ã–ª —Å—Ä–µ–∑ ¬´–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã¬ª –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–∞–∑–±–æ—Ä —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        if ('cut0' in locals() and cut0) or ('cut1' in locals() and cut1):
            if verbose:
                print(f"[CUT] {pdf_path.name}: –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Ä–∞–∑–¥–µ–ª –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {i}, –¥–∞–ª—å–Ω–µ–π—à–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–ø—É—â–µ–Ω—ã", flush=True)
            break

    return pages


def ingest_txt(txt_path: Path, page_size_chars: int = 1800) -> List[Dict[str, Any]]:
    text = detect_text_file(txt_path).strip()
    # ‚úÇÔ∏è –æ—Ç—Ä–µ–∑–∞–µ–º –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—É
    text, _ = strip_tail_references(text)
    return split_text_to_pages(text, page_size_chars=page_size_chars)


# ================== –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å ==================

def choose_ocr_backend(requested: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π backend OCR —Å —É—á—ë—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫.
    priority: requested ‚Üí fallback tesseract ‚Üí 'none'
    """
    req = (requested or "").lower()
    if req == "easyocr" and EASY_AVAILABLE:
        return "easyocr"
    if req == "tesseract" and TESS_AVAILABLE:
        return "tesseract"
    if EASY_AVAILABLE:
        return "easyocr"
    if TESS_AVAILABLE:
        return "tesseract"
    return "none"  # OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω


def _easyocr_models_ready(model_dir: Path) -> bool:
    try:
        mdir = model_dir / "model"
        return mdir.exists() and any(mdir.iterdir())
    except Exception:
        return False


def process_one_file(
    f: Path,
    out_dir: Path,
    *,
    min_chars: int,
    ocr_mode: str,
    ocr_backend_eff: str,
    ocr_lang: str,
    dpi: int,
    verbose: bool,
    page_size_chars: int,
    easyocr_dir: Path,
    easyocr_use_gpu: bool,
    easyocr_allow_downloads: bool,
) -> Dict[str, Any]:
    """–ü—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ manifest). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç entry + –ø—É—Ç—å pages."""
    sha = file_sha1(f)
    stem = f.stem
    doc_id = stem  # —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ doc_id —Ä–µ—à–∞–µ–º –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ, –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è
    out_pages = out_dir / f"{doc_id}.pages.jsonl"

    # OCR init (EasyOCR –≤ —ç—Ç–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ; —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø–æ —Ñ–ª–∞–≥—É)
    easy_reader = None
    if ocr_mode != "never" and ocr_backend_eff == "easyocr":
        easy_reader = easyocr.Reader(
            ['ru', 'en'],
            gpu=easyocr_use_gpu,
            model_storage_directory=str(easyocr_dir),
            download_enabled=bool(easyocr_allow_downloads),
            verbose=False,
        )

    # –ü–∞—Ä—Å–∏–Ω–≥
    ext = f.suffix.lower()
    if ext == ".pdf":
        pages = ingest_pdf(
            f, ocr_mode=ocr_mode, ocr_backend=ocr_backend_eff, ocr_lang=ocr_lang,
            dpi=dpi, min_chars=min_chars, verbose=verbose, easy_reader=easy_reader
        )
    elif ext == ".docx":
        pages = ingest_docx(f, page_size_chars=page_size_chars)
    else:
        pages = ingest_txt(f, page_size_chars=page_size_chars)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    with out_pages.open("w", encoding="utf-8") as w:
        for p in pages:
            rec = {"doc_id": doc_id, "page": p.get("page", 1), "text": p.get("text", "")}
            w.write(json.dumps(rec, ensure_ascii=False) + "\n")

    empty_pages = sum(1 for p in pages if not (p.get("text") or "").strip())

    return {
        "doc_id": doc_id,
        "source_path": str(f),
        "pages": len(pages),
        "lang": "ru",
        "sha1": sha,
        "ocr_backend": ocr_backend_eff,
        "ocr_mode": ocr_mode,
        "ocr_lang": ocr_lang,
        "dpi": dpi,
        "min_chars": min_chars,
        "empty_pages": empty_pages,
        "out_pages": str(out_pages)
    }


def _decide_easyocr_gpu(ocr_gpu_arg: str) -> bool:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –¥–ª—è EasyOCR."""
    ocr_gpu_arg = (ocr_gpu_arg or "auto").lower()
    if ocr_gpu_arg == "cuda":
        return _TORCH_OK and torch.cuda.is_available()
    if ocr_gpu_arg == "cpu":
        return False
    # auto
    return _TORCH_OK and torch.cuda.is_available()


def main():
    ap = argparse.ArgumentParser("RAW -> data/*.pages.jsonl (+manifest) —Å OCR –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π DOCX/TXT")
    ap.add_argument("--input-dir", default="raw_docs", help="–ü–∞–ø–∫–∞ —Å PDF/DOCX/TXT (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)")
    ap.add_argument("--out-dir", default="data", help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å JSONL –∏ manifest.json")
    ap.add_argument("--force", action="store_true", help="–ü–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å –¥–∞–∂–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")

    # OCR-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —á–µ—Ä–µ–∑ env)
    ap.add_argument("--ocr-mode", choices=["auto","always","never"], default=os.getenv("OCR_MODE", "auto"),
                    help="auto: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞; always: OCR –Ω–∞ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö; never: –±–µ–∑ OCR")
    ap.add_argument("--ocr-backend", choices=["tesseract","easyocr"], default=os.getenv("OCR_BACKEND", "easyocr"),
                    help="–ñ–µ–ª–∞–µ–º—ã–π –¥–≤–∏–∂–æ–∫ OCR (–±—É–¥–µ—Ç –∞–≤—Ç–æ-—Ñ–æ–ª–ª–±–µ–∫)")
    ap.add_argument("--ocr-lang", default=os.getenv("TESS_LANG", "rus+eng"), help="–Ø–∑—ã–∫–∏ –¥–ª—è tesseract")
    ap.add_argument("--min-chars", type=int, default=int(os.getenv("MIN_CHARS", "60")),
                    help="–ü–æ—Ä–æ–≥ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ OCR –≤ —Ä–µ–∂–∏–º–µ auto")
    ap.add_argument("--dpi", type=int, default=int(os.getenv("OCR_DPI", "300")), help="DPI —Ä–µ–Ω–¥–µ—Ä–∞ –¥–ª—è tesseract")

    # EasyOCR/GPU
    ap.add_argument("--ocr-gpu", choices=["auto","cpu","cuda"], default=os.getenv("OCR_GPU", "auto"),
                    help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è EasyOCR (auto/cpu/cuda)")
    ap.add_argument("--easyocr-dir", default=os.getenv("EASYOCR_DIR", str(Path.home() / ".EasyOCR")),
                    help="–ö–∞—Ç–∞–ª–æ–≥ –¥–ª—è –º–æ–¥–µ–ª–µ–π EasyOCR")
    ap.add_argument("--easyocr-allow-downloads", action="store_true",
                    default=os.getenv("EASYOCR_ALLOW_DOWNLOADS", "0").lower() in ("1","true","yes"),
                    help="–†–∞–∑—Ä–µ—à–∏—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π EasyOCR –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ")

    # –ü—Ä–æ—á–µ–µ
    ap.add_argument("--workers", type=int, default=0, help="–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –ø–æ —Ñ–∞–π–ª–∞–º (0=CPU count)")
    ap.add_argument("--page-size-chars", type=int, default=1800, help="–†–∞–∑–º–µ—Ä ¬´–ø—Å–µ–≤–¥–æ-—Å—Ç—Ä–∞–Ω–∏—Ü—ã¬ª –¥–ª—è DOCX/TXT")
    ap.add_argument("--verbose", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥")

    args = ap.parse_args()

    in_dir = Path(args.input_dir)
    out_dir = Path(args.out_dir)
    ensure_dir(out_dir)

    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã
    allowed = {".pdf", ".docx", ".txt"}
    files: List[Path] = []
    for p in in_dir.rglob("*"):
        if not p.is_file():
            continue
        ext = p.suffix.lower()
        if ext not in allowed:
            continue
        name = p.name
        if name.startswith("~$"):  # –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã MS Office
            continue
        files.append(p)
    files = sorted(files)

    if not files:
        print(f"–í {in_dir} –Ω–µ—Ç pdf/docx/txt", file=sys.stderr, flush=True)
        return 1

    manifest_path = out_dir / "manifest.json"
    manifest: Dict[str, Any] = {"docs": []}
    if manifest_path.exists():
        try:
            manifest = json.loads(manifest_path.read_text(encoding="utf-8"))
            if not isinstance(manifest, dict) or "docs" not in manifest:
                manifest = {"docs": []}
        except Exception:
            manifest = {"docs": []}

    docs = manifest.get("docs", [])
    by_source: Dict[str, Dict[str, Any]] = {d.get("source_path"): d for d in docs if isinstance(d, dict)}
    existing_ids = {d.get("doc_id") for d in docs if isinstance(d, dict)}

    # –ü–ª–∞–Ω —Ä–∞–±–æ—Ç: –ø–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ –∏–ª–∏ --force
    plan: List[Path] = []
    for f in files:
        sha = file_sha1(f)
        prev = by_source.get(str(f))
        if args.force or not prev or prev.get("sha1") != sha:
            plan.append(f)
        elif args.verbose:
            try:
                rel = f.relative_to(in_dir)
            except Exception:
                rel = f
            print(f"‚Üí –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {rel}", flush=True)

    if not plan:
        print("–ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π ‚Äî –Ω–∏—á–µ–≥–æ –¥–µ–ª–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.", flush=True)
        return 0

    # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π OCR backend —Å —É—á—ë—Ç–æ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ
    ocr_backend_eff = choose_ocr_backend(args.ocr_backend)
    if ocr_backend_eff == "none":
        args.ocr_mode = "never"

    easyocr_dir = Path(args.easyocr_dir).expanduser()
    ensure_dir(easyocr_dir / "model")

    # EasyOCR warmup: –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∏ –º–æ–¥–µ–ª–µ–π –µ—â—ë –Ω–µ—Ç
    need_easy_warmup = (
        args.ocr_mode != "never"
        and ocr_backend_eff == "easyocr"
        and not _easyocr_models_ready(easyocr_dir)
    )
    if need_easy_warmup:
        print("‚è≥ EasyOCR warmup: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–æ–¥–∏–Ω —Ä–∞–∑)...", flush=True)
        use_gpu = _decide_easyocr_gpu(args.ocr_gpu)
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –æ–¥–∏–Ω —Ä–∞–∑ (–ø–æ —Ñ–ª–∞–≥—É)
        easyocr.Reader(['ru','en'], gpu=use_gpu,
                       model_storage_directory=str(easyocr_dir),
                       download_enabled=bool(args.easyocr_allow_downloads),
                       verbose=False)
        # –ø–µ—Ä–≤—ã–π –ø—Ä–æ–≥–æ–Ω ‚Äî –±–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ (–∏—Å–∫–ª—é—á–∞–µ–º –≥–æ–Ω–∫–∏)
        args.workers = 1

    # –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –ø–æ —Ñ–∞–π–ª–∞–º
    workers = args.workers or max(1, os.cpu_count() or 1)

    # –ï—Å–ª–∏ EasyOCR ‚Äî –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, —á—Ç–æ–±—ã –¥–∞—Ç—å CUDA —Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ
    easyocr_use_gpu = False
    if args.ocr_mode != "never" and ocr_backend_eff == "easyocr":
        if workers > 1:
            print("‚ö†Ô∏è EasyOCR: –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ workers=1 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∏ GPU.", flush=True)
            workers = 1
        easyocr_use_gpu = _decide_easyocr_gpu(args.ocr_gpu)
        print(f"EasyOCR init –ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è —Å GPU={easyocr_use_gpu}", flush=True)

    total = len(plan)
    print(f"üì¶ Ingest started: {total} files (workers={workers}, ocr={args.ocr_mode}/{ocr_backend_eff})", flush=True)

    results: List[Dict[str, Any]] = []
    t_start = perf_counter()

    if workers <= 1 or len(plan) == 1:
        for i, f in enumerate(plan, 1):
            t0 = perf_counter()
            try:
                r = process_one_file(
                    f, out_dir,
                    min_chars=args.min_chars,
                    ocr_mode=args.ocr_mode,
                    ocr_backend_eff=ocr_backend_eff,
                    ocr_lang=args.ocr_lang,
                    dpi=args.dpi,
                    verbose=args.verbose,
                    page_size_chars=args.page_size_chars,
                    easyocr_dir=easyocr_dir,
                    easyocr_use_gpu=easyocr_use_gpu,
                    easyocr_allow_downloads=False,  # –≤ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –∫–∞—á–∞–µ–º
                )
                results.append(r)
                dt = perf_counter() - t0
                print(f"[{i}/{total}] {f.name}: {r['pages']} pages, empty={r['empty_pages']}, ocr={r['ocr_backend']}/{r['ocr_mode']} ({dt:.2f}s)", flush=True)
            except Exception as e:
                print(f"[ERR] {f.name}: {e}", file=sys.stderr, flush=True)
    else:
        mp_ctx = mp.get_context("spawn")
        with ProcessPoolExecutor(max_workers=workers, mp_context=mp_ctx) as ex:
            futs = {
                ex.submit(
                    process_one_file, f, out_dir,
                    min_chars=args.min_chars,
                    ocr_mode=args.ocr_mode,
                    ocr_backend_eff=ocr_backend_eff,
                    ocr_lang=args.ocr_lang,
                    dpi=args.dpi,
                    verbose=args.verbose,
                    page_size_chars=args.page_size_chars,
                    easyocr_dir=easyocr_dir,
                    easyocr_use_gpu=False,  # –≤ –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–µ ‚Äî –±–µ–∑ CUDA
                    easyocr_allow_downloads=False,
                ): f for f in plan
            }
            done = 0
            for fut in as_completed(futs):
                f = futs[fut]
                try:
                    r = fut.result()
                    results.append(r)
                    done += 1
                    print(f"[{done}/{total}] {f.name}: {r['pages']} pages, empty={r['empty_pages']}, ocr={r['ocr_backend']}/{r['ocr_mode']}", flush=True)
                except Exception as e:
                    print(f"[ERR] {f.name}: {e}", file=sys.stderr, flush=True)

    # –û–±–Ω–æ–≤–ª—è–µ–º manifest –∏ —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º doc_id –ø—Ä–∏ –∫–æ–ª–ª–∏–∑–∏–∏
    for r in results:
        src = r["source_path"]
        doc_id = r["doc_id"]

        if doc_id in existing_ids:
            base = doc_id
            suf = 2
            while f"{base}_{suf}" in existing_ids:
                suf += 1
            new_id = f"{base}_{suf}"
            # –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º —Ñ–∞–π–ª jsonl
            op = Path(r["out_pages"])
            op_renamed = op.with_name(f"{new_id}.pages.jsonl")
            try:
                op.rename(op_renamed)
            except FileNotFoundError:
                pass
            r["doc_id"] = new_id
            r["out_pages"] = str(op_renamed)
            doc_id = new_id
        existing_ids.add(doc_id)

        prev = by_source.get(src)
        entry = {
            "doc_id": doc_id,
            "source_path": src,
            "pages": r["pages"],
            "lang": "ru",
            "sha1": r["sha1"],
            "ocr": (args.ocr_mode != "never" and ocr_backend_eff != "none"),
            "ocr_mode": r["ocr_mode"],
            "ocr_backend": r["ocr_backend"],
            "ocr_lang": r["ocr_lang"],
            "dpi": r["dpi"],
            "min_chars": r["min_chars"],
            "empty_pages": r["empty_pages"],
        }
        if prev:
            prev.update(entry)
        else:
            manifest["docs"].append(entry)

    manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding="utf-8")
    total_dt = perf_counter() - t_start
    print(f"\n–ì–æ—Ç–æ–≤–æ ‚úÖ: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ = {len(results)} –∑–∞ {total_dt:.2f}s. –û–±–Ω–æ–≤–ª—ë–Ω {manifest_path}", flush=True)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
